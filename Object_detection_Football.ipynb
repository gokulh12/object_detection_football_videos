{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "fn6q6epnd4O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/MyDrive/content_2"
      ],
      "metadata": {
        "id": "Y-9Dj4u8eq-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQnyefkvyMqq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the tensorflow model repository\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        " while \"models\" in pathlib.Path.cwd().parts:\n",
        "   os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        " !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "6jlYIz1FyQ0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install API\n",
        "%%bash\n",
        "cd /content/gdrive/MyDrive/content_2/models/research\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "psEw_VMTyVPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        " \n",
        "import tensorflow as tf\n",
        " \n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        " \n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "UFMM1dDgy6fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run model test\n",
        "!python /content/gdrive/MyDrive/content_2/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "V2SKPCrEzJcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save train and test TFrecords to directory\n",
        "%cd /content/gdrive/MyDrive/content_2\n",
        "!curl -L \"https://app.roboflow.com/ds/N0syuxJPXg?key=jIqlzNOpbK\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "metadata": {
        "id": "Ndwo0eCE_UMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select this for ssd mobilenet \n",
        "MODELS_CONFIG = {\n",
        "   'ssd_mobilenet_640': {\n",
        "       'model_name': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8',\n",
        "       'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config',\n",
        "       'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz',\n",
        "       'batch_size': 8\n",
        "   }\n",
        "}"
      ],
      "metadata": {
        "id": "0wpbk23cBszc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Select this for  ssd resnet\n",
        "MODELS_CONFIG = {\n",
        "   'ssd_resnet_640': {\n",
        "       'model_name': 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8',\n",
        "       'base_pipeline_file': 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config',\n",
        "       'pretrained_checkpoint': 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz',\n",
        "       'batch_size': 8\n",
        "   }\n",
        "}"
      ],
      "metadata": {
        "id": "ROGFW793hbhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select the required model and specify training parameter\n",
        "chosen_model = 'ssd_mobilenet_640'\n",
        "num_steps = 50000 \n",
        "num_eval_steps = 500\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] "
      ],
      "metadata": {
        "id": "UNxAae0kBcVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download pretrained weights\n",
        "%mkdir /content/gdrive/MyDrive/content_2/models/research/deploy/\n",
        "%cd /content/gdrive/MyDrive/content_2/models/research/deploy/\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "metadata": {
        "id": "bXhtORLeBrRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download base training configuration file\n",
        "%cd /content/gdrive/MyDrive/content_2/models/research/deploy\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ],
      "metadata": {
        "id": "V2XzDpdpBuZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_fname = '/content/gdrive/MyDrive/content_2/models/research/deploy/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/gdrive/MyDrive/content_2/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
        " \n",
        "def get_num_classes(pbtxt_fname):\n",
        "   from object_detection.utils import label_map_util\n",
        "   label_map = label_map_util.load_labelmap('/content/gdrive/MyDrive/content_2/test/teams_label_map.pbtxt')\n",
        "   categories = label_map_util.convert_label_map_to_categories(\n",
        "       label_map, max_num_classes=90, use_display_name=True)\n",
        "   category_index = label_map_util.create_category_index(categories)\n",
        "   return len(category_index.keys())\n",
        "num_classes = get_num_classes('/content/gdrive/MyDrive/content_2/test/teams_label_map.pbtxt')"
      ],
      "metadata": {
        "id": "i0rivHseB55y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "id": "VN15_pLsDeS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "%cd /content/gdrive/MyDrive/content_2/models/research/deploy\n",
        "print('writing custom configuration file')\n",
        "with open(pipeline_fname) as f:\n",
        "   s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "   # fine_tune_checkpoint\n",
        "   s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "              'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "     # tfrecord files train and test.\n",
        "   s = re.sub(\n",
        "       '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format('/content/gdrive/MyDrive/content_2/train/teams.tfrecord'), s)\n",
        "   s = re.sub(\n",
        "       '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format('/content/gdrive/MyDrive/content_2/test/teams.tfrecord'), s)\n",
        "   # label_map_path\n",
        "   s = re.sub(\n",
        "       'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format('/content/gdrive/MyDrive/content_2/train/teams_label_map.pbtxt'), s)\n",
        "   # Set training batch_size.\n",
        "   s = re.sub('batch_size: [0-9]+',\n",
        "              'batch_size: {}'.format(batch_size), s)\n",
        " \n",
        "   # Set training steps, num_steps\n",
        "   s = re.sub('num_steps: [0-9]+',\n",
        "              'num_steps: {}'.format(num_steps), s)\n",
        "   # Set number of classes num_classes.\n",
        "   s = re.sub('num_classes: [0-9]+',\n",
        "              'num_classes: {}'.format(num_classes), s)\n",
        "     #fine-tune checkpoint type\n",
        "   s = re.sub(\n",
        "       'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "      \n",
        "   f.write(s)"
      ],
      "metadata": {
        "id": "yLEYGXZFDjyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show model configuration file\n",
        "%cat /content/gdrive/MyDrive/content_2/models/research/deploy/pipeline_file.config"
      ],
      "metadata": {
        "id": "672GM7CXEaHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify directories\n",
        "pipeline_file = '/content/gdrive/MyDrive/content_2/models/research/deploy/pipeline_file.config'\n",
        "model_dir = '/content/gdrive/MyDrive/content_2/log_files'"
      ],
      "metadata": {
        "id": "Gth_UTUGFQ4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "!python /content/gdrive/MyDrive/content_2/models/research/object_detection/model_main_tf2.py \\\n",
        "   --pipeline_config_path={pipeline_file} \\\n",
        "   --model_dir={model_dir} \\\n",
        "   --alsologtostderr \\\n",
        "   --num_train_steps={num_steps} \\\n",
        "   --sample_1_of_n_eval_examples=1 \\\n",
        "   --num_eval_steps={num_eval_steps}"
      ],
      "metadata": {
        "id": "71LlboXpFV6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spicify directory where evaluation files will be saved\n",
        "testing_dir = '/content/gdrive/MyDrive/content_2/log_files/testing'"
      ],
      "metadata": {
        "id": "P7pkx4LpZyLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "!python /content/gdrive/MyDrive/content_2/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={testing_dir} \\\n",
        "    --checkpoint_dir={model_dir} "
      ],
      "metadata": {
        "id": "pCgsvk9J19Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#See list of log files\n",
        "%ls '/content/gdrive/MyDrive/content_2/log_files'"
      ],
      "metadata": {
        "id": "GXgnEel1ly4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run conversion script\n",
        "import re\n",
        "import numpy as np\n",
        "output_directory = '/content/gdrive/MyDrive/content_2/fine_tuned_model'\n",
        "#place the model weights you would like to export here\n",
        "last_model_path = '/content/gdrive/MyDrive/content_2/log_files/'\n",
        "print(last_model_path)\n",
        "!python /content/gdrive/MyDrive/content_2/models/research/object_detection/exporter_main_v2.py \\\n",
        "   --trained_checkpoint_dir {last_model_path} \\\n",
        "   --output_directory {output_directory} \\\n",
        "   --pipeline_config_path {pipeline_file}"
      ],
      "metadata": {
        "id": "ObqfPahtlzSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#recover the saved model\n",
        "pipeline_config = pipeline_file\n",
        "#generally you want to put the last ckpt from training in here\n",
        "model_dir = '/content/gdrive/MyDrive/content_2/log_files/ckpt-51'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "     model_config=model_config, is_training=False)\n",
        " \n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "     model=detection_model)\n",
        "ckpt.restore(os.path.join('/content/gdrive/MyDrive/content_2/log_files/ckpt-51'))\n",
        " \n",
        " \n",
        "def get_model_detection_function(model):\n",
        " \"\"\"Get a tf.function for detection.\"\"\"\n",
        " \n",
        " @tf.function\n",
        " def detect_fn(image):\n",
        "   \"\"\"Detect objects in image.\"\"\"\n",
        " \n",
        "   image, shapes = model.preprocess(image)\n",
        "   prediction_dict = model.predict(image, shapes)\n",
        "   detections = model.postprocess(prediction_dict, shapes)\n",
        " \n",
        "   return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        " \n",
        " return detect_fn\n",
        " \n",
        "detect_fn = get_model_detection_function(detection_model)"
      ],
      "metadata": {
        "id": "tr1qhSQrlzVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "metadata": {
        "id": "ZvPdpBxxpf_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#without random\n",
        "#map labels for inference decoding\n",
        "label_map_path = configs['eval_input_config'].label_map_path\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "   label_map,\n",
        "   max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "   use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "metadata": {
        "id": "IKIaDH0R87HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Directory to save output images with bounding boxes\n",
        "cd /content/gdrive/MyDrive/barca_bayern_box_images"
      ],
      "metadata": {
        "id": "SGz5ZXRbhHsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create bounding boxes on test images\n",
        "from PIL import Image\n",
        "from natsort import natsorted\n",
        "TEST_IMAGE_PATHS = natsorted(glob.glob('/content/gdrive/MyDrive/barca_bayern/*.jpg'))\n",
        "k=1\n",
        "for i in range(len(TEST_IMAGE_PATHS)):\n",
        "  image_path = TEST_IMAGE_PATHS[i]\n",
        "  test_image = Image.open(image_path)\n",
        "  image_np = load_image_into_numpy_array(test_image)\n",
        "\n",
        "  input_tensor = tf.convert_to_tensor(\n",
        "   np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "  detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "  label_id_offset = 1\n",
        "  image_np_with_detections = image_np.copy()\n",
        "  \n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "     image_np_with_detections,\n",
        "     detections['detection_boxes'][0].numpy(),\n",
        "     (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "     detections['detection_scores'][0].numpy(),\n",
        "     category_index,\n",
        "     use_normalized_coordinates=True,\n",
        "     max_boxes_to_draw=200,\n",
        "     min_score_thresh=.5,\n",
        "     agnostic_mode=False,\n",
        "     )\n",
        "\n",
        "  im = Image.fromarray(image_np_with_detections)\n",
        "  im.save(\"{}.jpeg\".format(k))\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(12,16))\n",
        "  plt.imshow(image_np_with_detections)\n",
        "  plt.show()\n",
        "\n",
        "  k += 1\n",
        "  print(k)\n",
        "  \n",
        "  \n",
        "  \n"
      ],
      "metadata": {
        "id": "0BgOrI_CWSL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Images to video\n",
        "import os\n",
        "from natsort import natsorted\n",
        "import moviepy.video.io.ImageSequenceClip\n",
        "image_folder='/content/gdrive/MyDrive/barca_bayern_box_images_2'\n",
        "fps=25\n",
        "\n",
        "image_files = [os.path.join(image_folder,img)\n",
        "               for img in natsorted(os.listdir(image_folder))\n",
        "               if img.endswith(\".jpeg\")]\n",
        "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=fps)\n",
        "clip.write_videofile('my_video.mp4')"
      ],
      "metadata": {
        "id": "AgIRb1YXvmVu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}